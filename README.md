# AIOps RCA Assistant - Databricks Integration

**Enterprise-grade Root Cause Analysis system for Azure Data Factory and Databricks**

---

## üéØ Quick Start

### Problem: Generic Databricks Error Messages?

If you're seeing alerts like this:
> "The event notification does not include the specific underlying reason or error details"

**You need to configure Databricks API credentials.** Follow the Quick Start below.

### ‚ö° 3-Step Fix (5 minutes)

```bash
# 1. Run setup
./setup_databricks.sh

# 2. Test connection
./test_databricks_connection.sh 204354054874177

# 3. Restart application
cd genai_rca_assistant && python main.py
```

**See**: [QUICKSTART.md](QUICKSTART.md) for detailed instructions.

---

## üìã Documentation

| Document | Purpose | Use When |
|----------|---------|----------|
| [QUICKSTART.md](QUICKSTART.md) | 5-minute fix guide | You want to fix generic errors NOW |
| [DATABRICKS_SETUP.md](DATABRICKS_SETUP.md) | Complete setup guide | You need detailed troubleshooting |
| [.env.example](.env.example) | Configuration template | Setting up environment variables |
| This README | Project overview | Understanding the system |

---

## üõ†Ô∏è Setup Tools

### Automated Setup

```bash
# Interactive setup wizard - answers all questions
./setup_databricks.sh
```

Prompts for:
- Databricks workspace URL
- Personal Access Token
- Saves to `.env` file
- Tests connection automatically

### Connection Testing

```bash
# Test with a specific run_id
./test_databricks_connection.sh <run_id>

# Example
./test_databricks_connection.sh 204354054874177
```

Verifies:
- ‚úÖ Credentials are loaded
- ‚úÖ API connection works
- ‚úÖ Error extraction succeeds
- ‚úÖ Creates test webhook payload

---

## üèóÔ∏è System Architecture

### Data Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Databricks Job  ‚îÇ
‚îÇ Fails           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Webhook (minimal data: job_id, run_id, "failed")
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RCA System (/databricks-monitor endpoint)      ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  1. Receive webhook                            ‚îÇ
‚îÇ  2. Log raw payload                            ‚îÇ
‚îÇ  3. Extract run_id                             ‚îÇ
‚îÇ  4. üîë Call Databricks Jobs API                ‚îÇ  ‚Üê Needs credentials
‚îÇ  5. Fetch full run details                     ‚îÇ
‚îÇ  6. Extract real error from task outputs       ‚îÇ
‚îÇ  7. Send detailed error to AI                  ‚îÇ
‚îÇ  8. Generate specific RCA                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ Detailed RCA with specific error
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Slack Alert     ‚îÇ
‚îÇ ITSM Ticket     ‚îÇ
‚îÇ Dashboard       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Why API Credentials Are Critical

| Without Credentials | With Credentials |
|---------------------|------------------|
| ‚ùå Only webhook data (generic) | ‚úÖ Full run details from API |
| ‚ùå "Job failed" message | ‚úÖ Actual exception/stack trace |
| ‚ùå No task-level details | ‚úÖ Which task failed, line numbers |
| ‚ùå Generic RCA | ‚úÖ Specific, actionable RCA |

**Example:**

```
WITHOUT CREDENTIALS:
"A Databricks job failed. The event notification does not include specific error details."

WITH CREDENTIALS:
"Databricks job 'etl_pipeline' failed with org.apache.spark.sql.AnalysisException:
Table or view not found: production.users_table at line 42 in notebook ETL_Transform.
The table may have been dropped or renamed."
```

---

## üîß Configuration

### Required Environment Variables

```bash
# Databricks API (REQUIRED for detailed errors)
DATABRICKS_HOST=https://adb-1234567890123456.7.azuredatabricks.net
DATABRICKS_TOKEN=dapi1234567890abcdef...

# RCA System
GEMINI_API_KEY=your-gemini-key
RCA_API_KEY=your-rca-secret

# Optional: ITSM Integration
ITSM_TOOL=jira
JIRA_DOMAIN=https://your-company.atlassian.net
JIRA_API_TOKEN=your-token

# Optional: Slack Notifications
SLACK_BOT_TOKEN=xoxb-your-token
SLACK_ALERT_CHANNEL=aiops-rca-alerts
```

See [.env.example](.env.example) for complete list.

### Getting Databricks Credentials

**Workspace URL:**
- Azure Portal ‚Üí Databricks ‚Üí Overview ‚Üí URL
- Format: `https://adb-XXXXXXXXXX.X.azuredatabricks.net`

**Personal Access Token:**
1. Open Databricks workspace
2. User Settings ‚Üí Access Tokens
3. Generate New Token (365 days)
4. Name: "RCA System"
5. Copy token (starts with `dapi`)

---

## üé® Features

### ‚úÖ Enhanced in This Version

- **Complete webhook payload logging** - Debug exactly what Databricks sends
- **Databricks Event Delivery support** - Handle official webhook format
- **Automatic API enrichment** - Fetch detailed errors automatically
- **Comprehensive error extraction** - Check all fields for error messages
- **Detailed logging** - Track every step of error extraction
- **Duplicate prevention** - No multiple alerts for same run
- **Fallback handling** - Graceful degradation if API unavailable

### üöÄ Core Features

- **Multi-source support**: Azure Data Factory + Databricks
- **AI-powered RCA**: Google Gemini for intelligent analysis
- **ITSM integration**: Auto-create Jira tickets
- **Slack notifications**: Real-time alerts
- **Deduplication**: Prevent duplicate tickets
- **Audit trail**: Complete action history
- **FinOps tagging**: Cost center tracking
- **Auto-remediation**: Trigger healing playbooks
- **WebSocket updates**: Real-time dashboard

---

## üìÇ Project Structure

```
latest_databricks/
‚îú‚îÄ‚îÄ README.md                          # This file
‚îú‚îÄ‚îÄ QUICKSTART.md                      # 5-minute setup guide
‚îú‚îÄ‚îÄ DATABRICKS_SETUP.md               # Detailed troubleshooting
‚îú‚îÄ‚îÄ .env.example                       # Configuration template
‚îú‚îÄ‚îÄ setup_databricks.sh               # Interactive setup wizard ‚≠ê
‚îú‚îÄ‚îÄ test_databricks_connection.sh     # Connection testing ‚≠ê
‚îú‚îÄ‚îÄ databricks_debug_commands.sh      # Azure diagnostics
‚îÇ
‚îú‚îÄ‚îÄ genai_rca_assistant/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                       # FastAPI application (enhanced)
‚îÇ   ‚îú‚îÄ‚îÄ databricks_api_utils.py      # Databricks API client (enhanced)
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.html                # Web UI
‚îÇ   ‚îú‚îÄ‚îÄ login.html                    # Authentication
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ .env                          # Your credentials (created by setup)
‚îÇ
‚îî‚îÄ‚îÄ prompts/
    ‚îî‚îÄ‚îÄ rca_prompt.txt                # AI prompt templates
```

**‚≠ê New Tools** - Make setup and testing easy!

---

## üß™ Testing

### Test 1: Databricks API Connection

```bash
# Test with actual run_id from your alerts
./test_databricks_connection.sh 204354054874177
```

Expected output:
```
‚úÖ TEST PASSED: Successfully connected to Databricks API
‚úÖ Run details fetched successfully
‚úÖ Error extraction working

=== Run Details ===
Job ID: 404831337617650
Run ID: 204354054874177
Run Name: test4
State: TERMINATED
Result: FAILED

=== Error Message ===
[Task: notebook_task] org.apache.spark.sql.AnalysisException: ...
```

### Test 2: Full Webhook Flow

```bash
# Send test webhook to your running application
curl -X POST http://localhost:8000/databricks-monitor \
  -H "Content-Type: application/json" \
  -d '{
    "event": "on_failure",
    "run_id": "204354054874177",
    "job_id": "404831337617650"
  }'
```

Check logs for:
- ‚úÖ Webhook received
- ‚úÖ API fetch attempted
- ‚úÖ Detailed error extracted
- ‚úÖ Specific RCA generated

### Test 3: Create Failing Job in Databricks

```python
# In Databricks notebook
raise Exception("TEST: RCA system verification - table not found")

# Or
spark.sql("SELECT * FROM non_existent_table")
```

Run job ‚Üí Check RCA alert ‚Üí Should show specific error, not generic.

---

## üêõ Troubleshooting

### Issue: Generic Error Messages

**Symptom:**
```
Root Cause: The event notification does not include the specific
underlying reason or error details for why the Databricks job failed.
```

**Diagnosis:**
```bash
# Check if credentials configured
cat genai_rca_assistant/.env | grep DATABRICKS

# Test API connection
./test_databricks_connection.sh 204354054874177
```

**Fix:**
```bash
./setup_databricks.sh
```

### Issue: "DATABRICKS_HOST not set"

**Cause:** Environment variables not loaded

**Fix:**
```bash
# Check .env exists
ls -la genai_rca_assistant/.env

# Restart application to load .env
cd genai_rca_assistant
source .env
python main.py
```

### Issue: "401 Unauthorized"

**Cause:** Token expired or invalid

**Fix:**
1. Generate new token in Databricks UI
2. Run: `./setup_databricks.sh` (will update token)
3. Restart application

### Issue: Duplicate Alerts

**Cause:** Multiple webhooks for same run (now prevented)

**Verification:**
```bash
# Check logs for deduplication
tail -f app.log | grep "DUPLICATE DETECTED"
```

Should see:
```
DUPLICATE DETECTED: run_id 204354054874177 already has ticket DBX-...
```

---

## üìä Monitoring

### Application Logs

**Key log patterns to monitor:**

‚úÖ **Successful flow:**
```
================================================================================
DATABRICKS WEBHOOK RECEIVED - RAW PAYLOAD:
...
üìã Extracted from webhook: job_name=test4, run_id=204354054874177
üîÑ Attempting to fetch detailed error from Databricks Jobs API
‚úÖ Successfully fetched run details from Databricks API
‚úÖ Extracted detailed error from API: [Task: ...] ...
üì§ FINAL error_message being sent to RCA AI:
   API fetch attempted: True
   API fetch success: True
   Error message length: 245 chars
================================================================================
```

‚ùå **Missing credentials:**
```
‚ùå CRITICAL: Databricks API credentials NOT configured!
‚ùå Cannot fetch detailed error messages from Databricks Jobs API
```

‚ö†Ô∏è **API fetch failed:**
```
‚ùå Databricks API fetch returned None
‚ùå Falling back to webhook error_message (may be generic)
```

### Metrics to Track

- **API fetch success rate**: Should be > 95%
- **Error message length**: Should be > 100 chars (not generic)
- **Duplicate prevention**: Count of "DUPLICATE DETECTED" logs
- **RCA specificity**: Check for specific error types vs "UnknownError"

---

## üöÄ Deployment

### Local Development

```bash
cd genai_rca_assistant
pip install -r requirements.txt
source .env
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY genai_rca_assistant/ .
COPY .env.example .env

RUN pip install -r requirements.txt

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
docker build -t rca-system .
docker run -p 8000:8000 --env-file genai_rca_assistant/.env rca-system
```

### Azure App Service

```bash
# Deploy code
az webapp up \
  --name your-rca-app \
  --resource-group rg_techdemo_2025_Q4 \
  --runtime "PYTHON:3.11"

# Configure environment variables
az webapp config appsettings set \
  --name your-rca-app \
  --resource-group rg_techdemo_2025_Q4 \
  --settings \
    DATABRICKS_HOST="https://adb-123...azuredatabricks.net" \
    DATABRICKS_TOKEN="dapi..." \
    GEMINI_API_KEY="..." \
    RCA_API_KEY="..."
```

---

## ü§ù Contributing

### Code Enhancements Made

1. **main.py** (lines 1090-1212):
   - Complete raw webhook payload logging
   - Support for Databricks Event Delivery format
   - Enhanced error extraction from nested objects
   - Detailed API fetch status tracking

2. **databricks_api_utils.py** (lines 53-67, 155-246):
   - Prominent credential error messages
   - Step-by-step error extraction logging
   - Priority-based error field checking

3. **Documentation**:
   - QUICKSTART.md - Fast setup guide
   - DATABRICKS_SETUP.md - Complete reference
   - .env.example - All configuration options

4. **Tooling**:
   - setup_databricks.sh - Interactive setup
   - test_databricks_connection.sh - Verification

---

## üìÑ License

Enterprise Internal Use

---

## üìû Support

### Getting Help

1. **Quick issues**: Check [QUICKSTART.md](QUICKSTART.md)
2. **Setup problems**: See [DATABRICKS_SETUP.md](DATABRICKS_SETUP.md)
3. **Configuration**: Review [.env.example](.env.example)
4. **Testing**: Run `./test_databricks_connection.sh`

### Common Commands

```bash
# Setup from scratch
./setup_databricks.sh

# Test connection
./test_databricks_connection.sh <run_id>

# Check configuration
cat genai_rca_assistant/.env | grep DATABRICKS

# View logs
tail -f app.log | grep -A 10 "DATABRICKS WEBHOOK"

# Test API manually
cd genai_rca_assistant
python databricks_api_utils.py 204354054874177
```

---

## ‚úÖ Success Criteria

Your system is working correctly when:

- [ ] `./test_databricks_connection.sh` shows ‚úÖ TEST PASSED
- [ ] Application logs show "‚úÖ Successfully fetched run details from Databricks API"
- [ ] Error message length > 100 characters (not "Job failed")
- [ ] RCA alerts contain specific error details (table names, line numbers, etc.)
- [ ] No duplicate tickets for same run_id
- [ ] Resolution steps are actionable (not just "check logs")

---

**Version**: 2.0 (Enhanced Databricks Integration)
**Last Updated**: 2025-11-23
**Status**: Production Ready ‚úÖ
